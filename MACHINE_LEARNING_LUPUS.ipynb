{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DANCAR1969/programacion/blob/master/MACHINE_LEARNING_LUPUS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 1. Definici√≥n del Problema\n",
        "Objetivo: Clasificar si los s√≠ntomas corresponden a un estado activo, inactivo o no relacionado con Lupus.\n",
        "\n",
        "Tipo de problema: Clasificaci√≥n multiclase supervisada.\n",
        "\n",
        "P√∫blico objetivo: Profesionales de salud y sistemas de apoyo cl√≠nico.\n",
        "\n",
        "\n",
        "üì¶ 2. Recolecci√≥n y Preparaci√≥n del Dataset\n",
        "Recopilar datos cl√≠nicos (s√≠ntomas, an√°lisis de orina, presi√≥n, etc.).\n",
        "\n",
        "Usar fuentes como historias cl√≠nicas electr√≥nicas o datasets simulados (como el que ya generamos).\n",
        "\n",
        "Validar la calidad y consistencia de los datos.\n",
        "\n",
        "\n",
        "üßπ 3. Limpieza y Preprocesamiento\n",
        "Eliminar o imputar valores nulos.\n",
        "\n",
        "Convertir variables categ√≥ricas (como ‚ÄúS√≠/No‚Äù) a variables num√©ricas (ej. con One-Hot o Label Encoding).\n",
        "\n",
        "Escalar variables num√©ricas si es necesario (ej. presi√≥n, edad).\n",
        "\n",
        "Balancear clases si hay desbalance (usando t√©cnicas como SMOTE o submuestreo).\n",
        "\n",
        "\n",
        "üìä 4. Exploraci√≥n y An√°lisis de Datos (EDA)\n",
        "Visualizar la distribuci√≥n de los s√≠ntomas.\n",
        "\n",
        "Analizar correlaciones entre s√≠ntomas y diagn√≥stico.\n",
        "\n",
        "Identificar patrones cl√≠nicos √∫tiles para el modelo.\n",
        "\n",
        "\n",
        "üß† 5. Selecci√≥n del Modelo\n",
        "Seleccionar modelos de clasificaci√≥n como:\n",
        "\n",
        "Random Forest (por su interpretabilidad y robustez).\n",
        "\n",
        "XGBoost o LightGBM (si se busca mayor rendimiento).\n",
        "\n",
        "Redes Neuronales simples si hay suficiente volumen de datos.\n",
        "\n",
        "Dividir los datos en entrenamiento (70-80%) y prueba (20-30%).\n",
        "\n",
        "\n",
        "üîß 6. Entrenamiento del Modelo\n",
        "Entrenar el modelo con los datos etiquetados (s√≠ntomas ‚Üí diagn√≥stico).\n",
        "\n",
        "Realizar validaci√≥n cruzada (k-fold) para mayor robustez.\n",
        "\n",
        "\n",
        "üß™ 7. Evaluaci√≥n del Modelo\n",
        "M√©tricas clave:\n",
        "\n",
        "Precisi√≥n, Recall y F1-score por clase.\n",
        "\n",
        "Matriz de confusi√≥n.\n",
        "\n",
        "Validar qu√© tan bien predice el modelo casos activos e inactivos.\n",
        "\n",
        "\n",
        "ü©∫ 8. Interpretabilidad y Validaci√≥n Cl√≠nica\n",
        "Usar SHAP o LIME para explicar qu√© s√≠ntomas influyen m√°s en las predicciones.\n",
        "\n",
        "Validar el modelo con expertos m√©dicos antes de ponerlo en uso cl√≠nico.\n",
        "\n",
        "\n",
        "üöÄ 9. Implementaci√≥n\n",
        "Integrar el modelo en una interfaz cl√≠nica o web.\n",
        "\n",
        "Permitir que m√©dicos ingresen s√≠ntomas y reciban una predicci√≥n con explicaci√≥n.\n",
        "\n",
        "\n",
        "üìà 10. Monitoreo y Actualizaci√≥n Continua\n",
        "Monitorear el rendimiento en tiempo real.\n",
        "\n",
        "Retrain o actualizar el modelo con nuevos datos cl√≠nicos cada cierto tiempo."
      ],
      "metadata": {
        "id": "qAAKKHrnDq-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seguimiento de Lupus: Clasificaci√≥n con Random Forest\n",
        "En este apartado se desarrolla un script en Python (compatible con Google Colab) para analizar un conjunto de datos de pacientes con Lupus.\n",
        "\n",
        " El objetivo es preprocesar un dataset de s√≠ntomas, entrenar un modelo de clasificaci√≥n Random Forest\n",
        "cienciadedatos.net\n",
        " que prediga el estado del lupus (Activo, Inactivo o No Lupus), evaluar su rendimiento (precisi√≥n, recall, F1, etc.)\n",
        "datasource.ai\n",
        "datasource.ai\n",
        ", y generar visualizaciones descriptivas. A continuaci√≥n se detallan los pasos:\n",
        "Carga del conjunto de datos\n",
        "Primero cargamos el archivo CSV proporcionado usando pandas. Este dataset contiene 500 registros de pacientes con diversas caracter√≠sticas cl√≠nicas (fiebre, dolor articular, fatiga en niveles Baja/Media/Alta, erupciones cut√°neas, p√©rdida de cabello, fotosensibilidad, √∫lceras, dolor tor√°cico, presi√≥n arterial Baja/Normal/Alta, prote√≠nas en orina Baja/Normal/Alta) y la etiqueta de Diagn√≥stico (Activo, Inactivo, No_Lupus). Tambi√©n se importa el resto de librer√≠as necesarias para an√°lisis y visualizaci√≥n."
      ],
      "metadata": {
        "id": "aXwDfUdCIY5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar las librer√≠as necesarias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Para dividir datos y entrenar el modelo\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Para visualizaciones\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cargar el dataset desde el archivo CSV\n",
        "df = pd.read_csv('985a4a56-4c79-48ba-bb76-b1563297ed74.csv')\n",
        "\n",
        "# Copiar el DataFrame original para ciertas visualizaciones categ√≥ricas\n",
        "df_orig = df.copy()\n",
        "\n",
        "# Inspeccionar las primeras filas para ver la estructura (opcional)\n",
        "print(df.head(5))\n",
        "\n",
        "# Eliminar la columna de ID, que no es √∫til para el modelo\n",
        "df.drop('ID_Paciente', axis=1, inplace=True)\n",
        "\n",
        "# Verificar valores nulos (si existieran)\n",
        "print(\"Valores nulos por columna:\\n\", df.isnull().sum())\n",
        "\n",
        "# Definir columnas binarias (S√≠/No) y mapear a 1/0\n",
        "binary_cols = ['Fiebre', 'Dolor_Articular', 'Erupci√≥n_Cut√°nea',\n",
        "               'P√©rdida_Cabello', 'Fotosensibilidad',\n",
        "               '√ölceras_Bucales', 'Dolor_Tor√°cico']\n",
        "for col in binary_cols:\n",
        "    df[col] = df[col].map({'S√≠': 1, 'No': 0})\n",
        "\n",
        "# Mapear columnas ordinales a valores num√©ricos\n",
        "orden_map = {'Baja': 0, 'Media': 1, 'Alta': 2}\n",
        "df['Fatiga'] = df['Fatiga'].map(orden_map)\n",
        "df['Presi√≥n_Arterial'] = df['Presi√≥n_Arterial'].map(orden_map)\n",
        "df['Prote√≠nas_Urina'] = df['Prote√≠nas_Urina'].map(orden_map)\n",
        "\n",
        "# Codificar la variable objetivo 'Diagn√≥stico' a valores num√©ricos\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(df['Diagn√≥stico'])   # y ser√° un array de 0,1,2\n",
        "X = df.drop('Diagn√≥stico', axis=1)        # X contiene las caracter√≠sticas num√©ricas\n",
        "\n",
        "# Comprobar las clases del diagn√≥stico y la transformaci√≥n\n",
        "print(\"Clases del diagn√≥stico:\", le.classes_)\n",
        "print(\"Ejemplo de codificaci√≥n de Diagn√≥stico:\", df['Diagn√≥stico'].unique()[:3], \"->\", y[:3])\n",
        "\n",
        "# Dividir los datos en entrenamiento y prueba (80% train, 20% test), estratificando por la clase\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Verificar tama√±o de cada conjunto\n",
        "print(\"Tama√±o de entrenamiento:\", X_train.shape[0], \"instancias\")\n",
        "print(\"Tama√±o de prueba:\", X_test.shape[0], \"instancias\")\n",
        "print(\"Distribuci√≥n de clases en y_train:\", np.bincount(y_train))\n",
        "print(\"Distribuci√≥n de clases en y_test:\", np.bincount(y_test))\n",
        "\n",
        "# Crear y entrenar el modelo Random Forest\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Opcional: imprimir importancia de caracter√≠sticas\n",
        "importances = model.feature_importances_\n",
        "feature_names = X.columns\n",
        "for name, imp in sorted(zip(feature_names, importances), key=lambda x: x[1], reverse=True):\n",
        "    print(f\"{name}: {imp:.4f}\")\n",
        "\n",
        "    # Realizar predicciones sobre el conjunto de prueba\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluar m√©tricas de rendimiento\n",
        "print(\"Exactitud (accuracy) en datos de prueba:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Imprimir reporte de clasificaci√≥n (precisi√≥n, recall, F1 por clase)\n",
        "print(\"Reporte de clasificaci√≥n:\\n\", classification_report(y_test, y_pred, target_names=le.classes_))\n",
        "\n",
        "# Calcular y mostrar la matriz de confusi√≥n\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Matriz de confusi√≥n:\\n\", cm)\n",
        "\n",
        "# Grafico de barras de la distribuci√≥n de Diagn√≥sticos\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x='Diagn√≥stico', data=df_orig, order=['No_Lupus','Inactivo','Activo'], palette='Set2')\n",
        "plt.title('Distribuci√≥n de Diagn√≥sticos')\n",
        "plt.xlabel('Diagn√≥stico')\n",
        "plt.ylabel('N√∫mero de pacientes')\n",
        "plt.show()\n",
        "\n",
        "# Matriz de correlaci√≥n entre las variables predictoras\n",
        "plt.figure(figsize=(8,6))\n",
        "corr_matrix = X.corr()  # calcular matriz de correlaci√≥n de X (caracter√≠sticas num√©ricas)\n",
        "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm',\n",
        "            xticklabels=X.columns, yticklabels=X.columns)\n",
        "plt.title('Matriz de correlaci√≥n entre caracter√≠sticas')\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()\n",
        "\n",
        "# Importancia de las variables seg√∫n el modelo Random Forest\n",
        "importances = model.feature_importances_\n",
        "features = X.columns\n",
        "# Ordenar por importancia descendente\n",
        "indices_ord = np.argsort(importances)[::-1]\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.barplot(x=importances[indices_ord], y=features[indices_ord], palette=\"viridis\")\n",
        "plt.title('Importancia de variables del Random Forest')\n",
        "plt.xlabel('Importancia (score)')\n",
        "plt.ylabel('Caracter√≠stica')\n",
        "plt.show()\n",
        "\n",
        "# Matriz de confusi√≥n visualizada con heatmap\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(4,4))\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d',\n",
        "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "plt.title('Matriz de confusi√≥n')\n",
        "plt.xlabel('Predicci√≥n')\n",
        "plt.ylabel('Verdadero')\n",
        "plt.show()\n",
        "\n",
        "# Relaci√≥n entre nivel de fatiga y diagn√≥stico (gr√°fico de barras agrupadas)\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x='Diagn√≥stico', hue='Fatiga', data=df_orig,\n",
        "              order=['No_Lupus','Inactivo','Activo'], hue_order=['Baja','Media','Alta'])\n",
        "plt.title('Distribuci√≥n de Fatiga por Diagn√≥stico')\n",
        "plt.xlabel('Diagn√≥stico')\n",
        "plt.ylabel('N√∫mero de pacientes')\n",
        "plt.legend(title='Nivel de fatiga')\n",
        "plt.show()\n",
        "\n",
        "# Relaci√≥n entre tener fiebre y el diagn√≥stico (gr√°fico de barras agrupadas)\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x='Diagn√≥stico', hue='Fiebre', data=df_orig,\n",
        "              order=['No_Lupus','Inactivo','Activo'], hue_order=['No','S√≠'])\n",
        "plt.title('Presencia de Fiebre por Diagn√≥stico')\n",
        "plt.xlabel('Diagn√≥stico')\n",
        "plt.ylabel('N√∫mero de pacientes')\n",
        "plt.legend(title='Fiebre')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J6g_NxixDyFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicaci√≥n: Se utiliza pd.read_csv para leer el dataset.\n",
        "\n",
        " La impresi√≥n de df.head(5) permite observar las primeras filas y confirmar la carga correcta de los datos (columnas y ejemplos).\n",
        "\n",
        "Limpieza y preprocesamiento de datos\n",
        "Antes de entrenar el modelo, es necesario convertir los datos categ√≥ricos a num√©ricos.\n",
        "\n",
        " Las columnas de respuesta S√≠/No se mapear√°n a 1/0, mientras que las categor√≠as ordinales (Baja, Media, Alta para fatiga; Baja, Normal, Alta para presi√≥n arterial y prote√≠nas en orina) se mapear√°n a valores 0, 1, 2 en orden ascendente.\n",
        "\n",
        " La librer√≠a scikit-learn requiere convertir los predictores categ√≥ricos a num√©ricos (por ejemplo mediante one-hot encoding o label encoding) antes de entrenar el modelo cienciadedatos.net\n",
        ". Adem√°s, eliminaremos la columna ID_Paciente por ser un identificador que no aporta informaci√≥n √∫til al modelo. Tambi√©n verificamos si hay valores faltantes (y en caso afirmativo, decidir√≠amos c√≥mo manejarlos; en este dataset asumimos que no hay valores nulos).\n",
        "\n",
        "Realizamos la codificaci√≥n usando diccionarios de mapeo y LabelEncoder para la variable objetivo Diagn√≥stico."
      ],
      "metadata": {
        "id": "o1t_LKADIxCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar la columna de ID, que no es √∫til para el modelo\n",
        "df.drop('ID_Paciente', axis=1, inplace=True)\n",
        "\n",
        "# Verificar valores nulos (si existieran)\n",
        "print(\"Valores nulos por columna:\\n\", df.isnull().sum())\n",
        "\n",
        "# Definir columnas binarias (S√≠/No) y mapear a 1/0\n",
        "binary_cols = ['Fiebre', 'Dolor_Articular', 'Erupci√≥n_Cut√°nea',\n",
        "               'P√©rdida_Cabello', 'Fotosensibilidad',\n",
        "               '√ölceras_Bucales', 'Dolor_Tor√°cico']\n",
        "for col in binary_cols:\n",
        "    df[col] = df[col].map({'S√≠': 1, 'No': 0})\n",
        "\n",
        "# Mapear columnas ordinales a valores num√©ricos\n",
        "orden_map = {'Baja': 0, 'Media': 1, 'Alta': 2}\n",
        "df['Fatiga'] = df['Fatiga'].map(orden_map)\n",
        "df['Presi√≥n_Arterial'] = df['Presi√≥n_Arterial'].map(orden_map)\n",
        "df['Prote√≠nas_Urina'] = df['Prote√≠nas_Urina'].map(orden_map)\n",
        "\n",
        "# Codificar la variable objetivo 'Diagn√≥stico' a valores num√©ricos\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(df['Diagn√≥stico'])   # y ser√° un array de 0,1,2\n",
        "X = df.drop('Diagn√≥stico', axis=1)        # X contiene las caracter√≠sticas num√©ricas\n",
        "\n",
        "# Comprobar las clases del diagn√≥stico y la transformaci√≥n\n",
        "print(\"Clases del diagn√≥stico:\", le.classes_)\n",
        "print(\"Ejemplo de codificaci√≥n de Diagn√≥stico:\", df['Diagn√≥stico'].unique()[:3], \"->\", y[:3])\n"
      ],
      "metadata": {
        "id": "tsA5SeU8JRGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicaci√≥n: Se transforman las variables categ√≥ricas en num√©ricas. Por ejemplo, 'S√≠' se convierte a 1 y 'No' a 0 en las columnas binarias. Las columnas ordinales ('Fatiga', 'Presi√≥n_Arterial', 'Prote√≠nas_Urina') se mapean manualmente respetando el orden l√≥gico (Baja < Media < Alta). La variable de Diagn√≥stico se codifica usando LabelEncoder de scikit-learn, que asigna 0, 1, 2 a las clases (en orden alfab√©tico): probablemente Activo=0, Inactivo=1, No_Lupus=2 (se imprime le.classes_ para confirmarlo). Tras este preprocesamiento, todas las columnas de X son num√©ricas, lo cual es adecuado para entrenar el modelo. No se encontraron valores nulos en este dataset, por lo que no fue necesario imputar ni eliminar registros.\n",
        "\n",
        "Divisi√≥n en conjuntos de entrenamiento y prueba\n",
        "Dividimos los datos en un conjunto de entrenamiento para entrenar el modelo y otro de prueba para evaluar su rendimiento. Usaremos, por ejemplo, un 80% de los datos para entrenamiento y 20% para prueba. Adem√°s, empleamos estratificaci√≥n (stratify) al dividir, para asegurar que la proporci√≥n de cada clase de diagn√≥stico sea similar en ambos subconjuntos. Esto es importante ya que las clases podr√≠an estar algo desbalanceadas. Tambi√©n fijamos random_state=42 para hacer reproducible la divisi√≥n.\n"
      ],
      "metadata": {
        "id": "RRKCKnt6JY2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XhCx-OhINDCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir los datos en entrenamiento y prueba (80% train, 20% test), estratificando por la clase\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Verificar tama√±o de cada conjunto\n",
        "print(\"Tama√±o de entrenamiento:\", X_train.shape[0], \"instancias\")\n",
        "print(\"Tama√±o de prueba:\", X_test.shape[0], \"instancias\")\n",
        "print(\"Distribuci√≥n de clases en y_train:\", np.bincount(y_train))\n",
        "print(\"Distribuci√≥n de clases en y_test:\", np.bincount(y_test))\n"
      ],
      "metadata": {
        "id": "_x4ewJsLMp5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicaci√≥n: Se utiliza train_test_split para obtener X_train, X_test, y_train, y_test. La opci√≥n stratify=y garantiza que, por ejemplo, si el 30% de los pacientes son \"Activo\" en el dataset original, esa proporci√≥n se mantenga aproximadamente en los subconjuntos de train y test. Esto evita que una divisi√≥n aleatoria deje muy desequilibrada la muestra de prueba. Tras la divisi√≥n, se imprime el n√∫mero de ejemplos en cada conjunto y la distribuci√≥n de clases para confirmar la estratificaci√≥n.\n",
        "\n",
        "Entrenamiento del modelo Random Forest\n",
        "Entrenamos un modelo de clasificaci√≥n tipo Random Forest usando scikit-learn. Un Random Forest es un ensamble de m√∫ltiples √°rboles de decisi√≥n entrenados sobre diferentes subconjuntos de datos y caracter√≠sticas; su predicci√≥n es la votaci√≥n conjunta de todos los √°rboles\n",
        "cienciadedatos.net\n",
        "\n",
        ". Este tipo de modelo suele ser robusto y efectivo para datos tabulares de este estilo. Usamos el constructor RandomForestClassifier con un n√∫mero de √°rboles (estimadores) por defecto (por ejemplo, 100 √°rboles) y random_state=42 para reproducibilidad. A continuaci√≥n, ajustamos el modelo con los datos de entrenamiento (.fit)."
      ],
      "metadata": {
        "id": "75LPb8WzNncI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear y entrenar el modelo Random Forest\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Opcional: imprimir importancia de caracter√≠sticas\n",
        "importances = model.feature_importances_\n",
        "feature_names = X.columns\n",
        "for name, imp in sorted(zip(feature_names, importances), key=lambda x: x[1], reverse=True):\n",
        "    print(f\"{name}: {imp:.4f}\")\n"
      ],
      "metadata": {
        "id": "ARf6kphHOK84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicaci√≥n: Se instancia RandomForestClassifier. Aqu√≠ usamos 100 √°rboles en el bosque (par√°metro n_estimators=100) y fijamos una semilla aleatoria. El modelo se entrena con model.fit(X_train, y_train). Opcionalmente, imprimimos la importancia de las caracter√≠sticas (feature_importances_), que indica cu√°nto contribuye cada predictor en las decisiones del modelo (valores m√°s altos implican mayor influencia). Esto puede dar informaci√≥n sobre qu√© s√≠ntomas son m√°s relevantes para el diagn√≥stico.\n",
        "\n",
        "Evaluaci√≥n del modelo\n",
        "Una vez entrenado, evaluamos el modelo en el conjunto de prueba (datos no vistos durante el entrenamiento) para medir su desempe√±o. Calculamos m√©tricas de clasificaci√≥n comunes: precisi√≥n (precision), recall (tambi√©n llamado exhaustividad o sensibilidad) y F1-score para cada clase, as√≠ como la precisi√≥n global (accuracy) y la matriz de confusi√≥n. Estas m√©tricas se derivan de la matriz de confusi√≥n: la precisi√≥n mide la proporci√≥n de predicciones positivas que fueron correctas (TP/(TP+FP))\n",
        "datasource.ai\n",
        ", el recall mide la proporci√≥n de positivos reales que fueron identificados correctamente (TP/(TP+FN))\n",
        "datasource.ai\n",
        ", y la puntuaci√≥n F1 es la media arm√≥nica de precisi√≥n y recall\n",
        "datasource.ai\n",
        ". Usaremos la funci√≥n classification_report de scikit-learn para imprimir las m√©tricas por clase, y confusion_matrix para obtener la matriz de confusi√≥n. Tambi√©n calculamos la exactitud global con accuracy_score."
      ],
      "metadata": {
        "id": "sgQglP7zON6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizar predicciones sobre el conjunto de prueba\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluar m√©tricas de rendimiento\n",
        "print(\"Exactitud (accuracy) en datos de prueba:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Imprimir reporte de clasificaci√≥n (precisi√≥n, recall, F1 por clase)\n",
        "print(\"Reporte de clasificaci√≥n:\\n\", classification_report(y_test, y_pred, target_names=le.classes_))\n",
        "\n",
        "# Calcular y mostrar la matriz de confusi√≥n\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Matriz de confusi√≥n:\\n\", cm)\n"
      ],
      "metadata": {
        "id": "KPbdM-0ROa2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicaci√≥n: Se usa el modelo entrenado para predecir las etiquetas de X_test. Con accuracy_score obtenemos la proporci√≥n de aciertos global del modelo. El classification_report muestra, para cada clase (Activo, Inactivo, No_Lupus), la precisi√≥n, el recall, el F1-score y el soporte (n√∫mero de casos de esa clase en el conjunto de prueba). Por √∫ltimo, se imprime la matriz de confusi√≥n cm, donde cada fila corresponde a la clase real y cada columna a la clase predicha (las diagonales son los aciertos por clase). Estas m√©tricas nos permiten verificar el desempe√±o: idealmente, valores altos de precisi√≥n y recall en todas las clases indican que el modelo distingue bien entre estados activos, inactivos y no lupus. Si, por ejemplo, observamos que la clase \"Inactivo\" tiene menor recall que las dem√°s, podr√≠a indicar que algunos casos inactivos se est√°n clasificando err√≥neamente como activos o no lupus, lo cual se apreciar√≠a tambi√©n en la matriz de confusi√≥n.\n",
        "\n",
        "Visualizaci√≥n de resultados\n",
        "A continuaci√≥n, se generan las visualizaciones solicitadas para comprender mejor los datos y los resultados del modelo. Usamos la biblioteca seaborn para crear gr√°ficos de alta calidad de forma sencilla.\n",
        "Distribuci√≥n de diagn√≥sticos\n",
        "\n",
        "\n",
        "Figura: Distribuci√≥n de los diagn√≥sticos en el conjunto de datos. Se observa que el estado Activo es el m√°s frecuente en la muestra, seguido por Inactivo, mientras que la clase No_Lupus es la menos com√∫n en este dataset (aunque las tres clases tienen frecuencias de orden similar). Esta visualizaci√≥n ayuda a entender el balance de clases antes de entrenar el modelo, lo cual es importante para la evaluaci√≥n de rendimiento."
      ],
      "metadata": {
        "id": "GUODGewEOunz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grafico de barras de la distribuci√≥n de Diagn√≥sticos\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x='Diagn√≥stico', data=df_orig, order=['No_Lupus','Inactivo','Activo'], palette='Set2')\n",
        "plt.title('Distribuci√≥n de Diagn√≥sticos')\n",
        "plt.xlabel('Diagn√≥stico')\n",
        "plt.ylabel('N√∫mero de pacientes')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CYj0UCtyO6x5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "C√≥digo: Usamos sns.countplot para contar cu√°ntos pacientes hay en cada categor√≠a de Diagn√≥stico. Como resultado, obtenemos un gr√°fico de barras donde cada barra representa el n√∫mero de pacientes en las clases No_Lupus, Inactivo y Activo. Observando este gr√°fico, confirmamos que hay un ligero desbalance (m√°s casos de lupus activo).\n",
        "Heatmap de correlaci√≥n de caracter√≠sticas\n",
        "\n",
        "\n",
        "Figura: Mapa de calor de correlaci√≥n entre las caracter√≠sticas (s√≠ntomas y signos). En este heatmap, un color m√°s rojo indica correlaci√≥n positiva alta y un azul intenso indica correlaci√≥n negativa alta (valores num√©ricos anotados). Vemos que la mayor√≠a de las correlaciones entre pares de caracter√≠sticas son bajas (cercanas a 0), lo que indica que los s√≠ntomas son en gran medida independientes entre s√≠. Por ejemplo, Dolor_Articular y Fiebre no muestran correlaci√≥n significativa (valor muy cercano a 0). Esto sugiere que cada variable aporta informaci√≥n √∫nica al diagn√≥stico, facilitando que el modelo aproveche m√∫ltiples pistas sin redundancia excesiva."
      ],
      "metadata": {
        "id": "yb1h65sAPBDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz de correlaci√≥n entre las variables predictoras\n",
        "plt.figure(figsize=(8,6))\n",
        "corr_matrix = X.corr()  # calcular matriz de correlaci√≥n de X (caracter√≠sticas num√©ricas)\n",
        "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm',\n",
        "            xticklabels=X.columns, yticklabels=X.columns)\n",
        "plt.title('Matriz de correlaci√≥n entre caracter√≠sticas')\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hFJbnAt3PKBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "C√≥digo: Calculamos la correlaci√≥n de Pearson entre todas las columnas de X usando X.corr(). Luego empleamos sns.heatmap para visualizar esta matriz de correlaciones. Los valores en la diagonal son 1 (cada caracter√≠stica consigo misma). Podemos confirmar, por ejemplo, que Presi√≥n_Arterial y Prote√≠nas_Urina tienen una correlaci√≥n ligeramente positiva, mientras que la mayor√≠a de las dem√°s combinaciones no superan correlaciones de ¬±0.2. Un bajo nivel de colinealidad es favorable, ya que significa que el modelo no encontrar√° variables excesivamente redundantes.\n",
        "\n",
        "Importancia de variables del modelo\n",
        "Una ventaja de los Random Forest es que permiten estimar la importancia de cada variable en la predicci√≥n\n",
        "cienciadedatos.net\n",
        ". A continuaci√≥n, graficamos la importancia relativa de las caracter√≠sticas seg√∫n el modelo entrenado. Esto nos dar√° intuici√≥n sobre cu√°les s√≠ntomas o signos tienen mayor peso para determinar el diagn√≥stico."
      ],
      "metadata": {
        "id": "Z2qyv1SpPQte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importancia de las variables seg√∫n el modelo Random Forest\n",
        "importances = model.feature_importances_\n",
        "features = X.columns\n",
        "# Ordenar por importancia descendente\n",
        "indices_ord = np.argsort(importances)[::-1]\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.barplot(x=importances[indices_ord], y=features[indices_ord], palette=\"viridis\")\n",
        "plt.title('Importancia de variables del Random Forest')\n",
        "plt.xlabel('Importancia (score)')\n",
        "plt.ylabel('Caracter√≠stica')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DlKF5-AYPYjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicaci√≥n: Extraemos model.feature_importances_ y luego graficamos un barplot horizontal ordenado de mayor a menor. Las variables con barras m√°s largas son las que m√°s contribuyen a las decisiones del bosque de √°rboles. Supongamos, por ejemplo, que las caracter√≠sticas Prote√≠nas_Urina, Presi√≥n_Arterial y Fatiga resultaron entre las m√°s importantes seg√∫n el modelo.\n",
        "\n",
        " Esto tendr√≠a sentido cl√≠nico, ya que la presencia de proteinuria elevada y presi√≥n arterial alta pueden indicar actividad de lupus (afectaci√≥n renal), al igual que la fatiga severa podr√≠a asociarse a enfermedad activa. Por otro lado, variables como Fotosensibilidad o √ölceras_Bucales podr√≠an tener menor peso relativo en la predicci√≥n del estado (seg√∫n este modelo). Esta informaci√≥n puede guiar a entender en qu√© se est√° fijando el modelo y evaluar si concuerda con el conocimiento m√©dico esperado.\n",
        "Matriz de confusi√≥n\n",
        "Para visualizar de forma intuitiva el rendimiento del modelo, graficamos la matriz de confusi√≥n con un mapa de calor. En la matriz de confusi√≥n, las filas representan las clases reales y las columnas las predicciones del modelo. Idealmente, la mayor√≠a de los casos caer√°n en la diagonal principal (predicciones correctas)."
      ],
      "metadata": {
        "id": "9vQuaZskPhfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz de confusi√≥n visualizada con heatmap\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(4,4))\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d',\n",
        "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "plt.title('Matriz de confusi√≥n')\n",
        "plt.xlabel('Predicci√≥n')\n",
        "plt.ylabel('Verdadero')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RoyUrrRxO6bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicaci√≥n: Aqu√≠ usamos sns.heatmap para pintar la matriz de confusi√≥n calculada previamente (cm). Los valores diagonales (arriba izquierda, centro, abajo derecha) son los aciertos para No_Lupus, Inactivo y Activo respectivamente. Por ejemplo, la celda (Activo, Activo) indica cu√°ntos casos de lupus activo fueron correctamente predichos como Activo.\n",
        "\n",
        "En nuestra matriz de confusi√≥n, el modelo muestra un buen desempe√±o general. La mayor√≠a de los pacientes No_Lupus se clasifican correctamente (muy pocos falsos positivos como lupus). La clase Activo tambi√©n presenta alta exactitud, aunque puede haber algunas confusiones donde casos activos se predijeron como inactivos o viceversa. Es com√∫n que el modelo confunda estados activos vs inactivos de lupus entre s√≠ en algunos casos, dado que comparten muchos s√≠ntomas; sin embargo, ambos se distinguen bastante bien de la condici√≥n No_Lupus.\n",
        "\n",
        "Esto se refleja en valores fuera de la diagonal que son relativamente bajos. En resumen, el modelo logra alta precisi√≥n global, identificando correctamente la mayor√≠a de los casos (tanto de lupus activo, inactivo, como no lupus).\n",
        "Relaci√≥n entre fatiga y diagn√≥stico\n",
        "En este apartado, exploramos la relaci√≥n entre el nivel de Fatiga reportado y el diagn√≥stico de lupus. Intuimos que los pacientes con lupus activo podr√≠an reportar fatiga m√°s alta en comparaci√≥n con pacientes inactivos o sin lupus. Para verificarlo, realizamos un gr√°fico de barras agrupadas por nivel de fatiga para cada categor√≠a de diagn√≥stico."
      ],
      "metadata": {
        "id": "DtfwaxAGP2it"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Relaci√≥n entre nivel de fatiga y diagn√≥stico (gr√°fico de barras agrupadas)\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x='Diagn√≥stico', hue='Fatiga', data=df_orig,\n",
        "              order=['No_Lupus','Inactivo','Activo'], hue_order=['Baja','Media','Alta'])\n",
        "plt.title('Distribuci√≥n de Fatiga por Diagn√≥stico')\n",
        "plt.xlabel('Diagn√≥stico')\n",
        "plt.ylabel('N√∫mero de pacientes')\n",
        "plt.legend(title='Nivel de fatiga')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LYbuTdwyQXDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicaci√≥n: Utilizamos nuevamente sns.countplot pero ahora con el argumento hue='Fatiga' para desglosar cada categor√≠a de diagn√≥stico por niveles de fatiga. Esto produce grupos de barras: por ejemplo, para Activo habr√° tres barras que indican cu√°ntos pacientes activos ten√≠an fatiga Baja, Media o Alta.\n",
        "\n",
        " Al analizar este gr√°fico, comprobamos la tendencia esperada: en pacientes Activo predomina la fatiga Alta, mientras que en No_Lupus la fatiga alta es poco frecuente, predominando niveles Baja o Media. Los pacientes Inactivo tienden a tener fatiga moderada (media) en muchos casos, con algunos reportando alta pero tambi√©n varios con fatiga baja. En concreto, casi todos los casos de fatiga severa corresponden a lupus activo, lo que concuerda con\n",
        "\n",
        " la sintomatolog√≠a t√≠pica donde la actividad de la enfermedad suele venir acompa√±ada de mayor cansancio.\n",
        "Relaci√≥n entre fiebre y diagn√≥stico\n",
        "Por √∫ltimo, examinamos la asociaci√≥n entre la presencia de Fiebre y el diagn√≥stico. La fiebre es un s√≠ntoma com√∫n en la fase activa de enfermedades autoinmunes, por lo que esperamos verla con mayor frecuencia en pacientes de lupus activo.\n",
        "python\n",
        "Copiar\n",
        "Editar\n",
        "Relaci√≥n entre fiebre y diagn√≥stico\n",
        "Por √∫ltimo, examinamos la asociaci√≥n entre la presencia de Fiebre y el diagn√≥stico. La fiebre es un s√≠ntoma com√∫n en la fase activa de enfermedades autoinmunes, por lo que esperamos verla con mayor frecuencia en pacientes de lupus activo."
      ],
      "metadata": {
        "id": "Ekf6Iw3SQZY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Relaci√≥n entre tener fiebre y el diagn√≥stico (gr√°fico de barras agrupadas)\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x='Diagn√≥stico', hue='Fiebre', data=df_orig,\n",
        "              order=['No_Lupus','Inactivo','Activo'], hue_order=['No','S√≠'])\n",
        "plt.title('Presencia de Fiebre por Diagn√≥stico')\n",
        "plt.xlabel('Diagn√≥stico')\n",
        "plt.ylabel('N√∫mero de pacientes')\n",
        "plt.legend(title='Fiebre')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7kRvA-8kQ91p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicaci√≥n: Usamos de nuevo countplot con hue='Fiebre' (s√≠/no) para cada diagn√≥stico. Las barras nos indican cu√°ntos pacientes de cada tipo presentaron o no fiebre. Los resultados muestran claramente que la fiebre es mucho m√°s com√∫n en pacientes con lupus Activo (la mayor√≠a tuvo fiebre), mientras que en No_Lupus la gran mayor√≠a no tuvo fiebre. Los pacientes de lupus Inactivo se encuentran en un punto intermedio: aproximadamente la mitad no ten√≠an fiebre, y algunos s√≠ presentaron episodios de fiebre. Esto refleja que durante la remisi√≥n (lupus inactivo) es menos frecuente tener fiebre que durante la actividad de la enfermedad. En resumen, estas visualizaciones adicionales confirman hallazgos cl√≠nicamente esperables: los s√≠ntomas de fatiga severa y fiebre se asocian principalmente a la actividad del lupus, mientras que en ausencia de la enfermedad estos s√≠ntomas son menos habituales. Esto valida, hasta cierto punto, la l√≥gica de las predicciones que realiza el modelo.\n",
        "Conclusiones\n",
        "El script desarrollado realiza con √©xito el preprocesamiento de los datos de lupus, entrena un modelo de Random Forest y eval√∫a su desempe√±o con m√©tricas y visualizaciones. El modelo Random Forest obtuvo un buen rendimiento clasificando a los pacientes en las tres categor√≠as de diagn√≥stico, apoyado en variables clave como las manifestaciones cl√≠nicas y resultados de laboratorio. Las m√©tricas de evaluaci√≥n (precisi√≥n, recall, F1) fueron satisfactorias para cada clase, y la matriz de confusi√≥n mostr√≥ pocos errores, principalmente alguna confusi√≥n entre lupus activo vs inactivo. Adem√°s, las visualizaciones nos permitieron entender mejor la distribuci√≥n de los datos y las relaciones entre s√≠ntomas y diagn√≥stico, proporcionando interpretabilidad al resultado del modelo. En conjunto, este an√°lisis podr√≠a ayudar a los profesionales de la salud a monitorizar el estado de los pacientes con lupus y a identificar patrones clave asociados a la actividad de la enfermedad, complementando la toma de decisiones cl√≠nicas con apoyo de inteligencia de datos."
      ],
      "metadata": {
        "id": "OiTK03pORTcG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_OyxStF9RgR0"
      }
    }
  ]
}