{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP44AfqTXL6sUI7CjIF0t2B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DANCAR1969/programacion/blob/master/Modelopredictivocsv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modelo predictivo usando un CSV**"
      ],
      "metadata": {
        "id": "c2fmUUG5p4RY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El código realiza un análisis predictivo para detectar casos de depresión en estudiantes utilizando un modelo de clasificación basado en Random Forest. Incluye pasos clave como: carga y limpieza de datos, codificación de variables categóricas, normalización de características, división de datos en conjuntos de entrenamiento y prueba, entrenamiento del modelo y evaluación de su rendimiento."
      ],
      "metadata": {
        "id": "cPiOENmBpnLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Importar librerías necesarias\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import os\n",
        "\n",
        "# Verificar si el archivo existe\n",
        "ruta_archivo = r\"C:\\Users\\danie\\OneDrive\\Documentos\\student_depression_dataset.csv\" #\"C:\\Users\\danie\\Student Depression Dataset.csv\"\n",
        "\n",
        "if os.path.isfile(ruta_archivo):\n",
        "    # Cargar archivo CSV\n",
        "    data = pd.read_csv(ruta_archivo)\n",
        "    print(\"Primeras filas del archivo cargado:\\n\")\n",
        "    print(data.head())\n",
        "\n",
        "    # Limpieza de datos\n",
        "    # Eliminar filas con valores nulos\n",
        "    data.dropna(inplace=True)\n",
        "\n",
        "    # Codificación de variables categóricas\n",
        "    categorical_columns = ['Gender', 'City', 'Profession', 'Sleep Duration',\n",
        "                           'Dietary Habits', 'Degree', 'Have you ever had suicidal thoughts ?',\n",
        "                           'Family History of Mental Illness']\n",
        "\n",
        "    # Aplicar codificación a las columnas categóricas\n",
        "    label_encoders = {}\n",
        "    for col in categorical_columns:\n",
        "        le = LabelEncoder()\n",
        "        data[col] = le.fit_transform(data[col])\n",
        "        label_encoders[col] = le\n",
        "\n",
        "    # Normalización de características numéricas\n",
        "    numerical_columns = ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA',\n",
        "                         'Study Satisfaction', 'Job Satisfaction', 'Work/Study Hours',\n",
        "                         'Financial Stress']\n",
        "    scaler = MinMaxScaler()\n",
        "    data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
        "\n",
        "    # Separar características y variable objetivo\n",
        "    X = data.drop('Depression', axis=1)\n",
        "    y = data['Depression']\n",
        "\n",
        "    # Dividir datos en conjuntos de entrenamiento y prueba\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Crear y entrenar el modelo predictivo\n",
        "    model = RandomForestClassifier(random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Realizar predicciones\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluar el modelo\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred, target_names=['No Depression', 'Depression'])\n",
        "\n",
        "    # Mostrar resultados\n",
        "    print(f\"Precisión del modelo: {accuracy:.2%}\")\n",
        "    print(\"\\nReporte de clasificación:\\n\")\n",
        "    print(report)\n",
        "else:\n",
        "    print(f\"Error: El archivo no se encuentra en la ruta especificada: {ruta_archivo}\")"
      ],
      "metadata": {
        "id": "cbTspuQuJrtI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "411a5a93-3720-42ac-dc97-e3a7a9c0edb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: El archivo no se encuentra en la ruta especificada: C:\\Users\\danie\\Student Depression Dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fases del Código y Explicación Detallada\n",
        "\n",
        "1. Importación de Librerías"
      ],
      "metadata": {
        "id": "Jc9bsfO3qeym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import os\n"
      ],
      "metadata": {
        "id": "cvczE87rqu4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación:\n",
        "\n",
        "Importa librerías necesarias para la manipulación de datos (pandas), preprocesamiento (sklearn.preprocessing), división de datos (train_test_split), creación de modelos (RandomForestClassifier), y evaluación del rendimiento (accuracy_score, classification_report).\n",
        "Nos permite verificar si el archivo existe en una ruta específica."
      ],
      "metadata": {
        "id": "OjB_IMU2q45m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Verificación y Carga de Datos"
      ],
      "metadata": {
        "id": "uu8w3r_NrOrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ruta_archivo = \"C:/Users/danie/Student Depression Dataset.csv\"\n",
        "\n",
        "if os.path.isfile(ruta_archivo):\n",
        "    data = pd.read_csv(ruta_archivo)\n",
        "    print(\"Primeras filas del archivo cargado:\\n\")\n",
        "    print(data.head())\n",
        "else:\n",
        "    print(f\"Error: El archivo no se encuentra en la ruta especificada: {ruta_archivo}\")\n"
      ],
      "metadata": {
        "id": "d9FsjaC-rQng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación:\n",
        "\n",
        "Comprueba si el archivo existe en la ruta especificada.\n",
        "Si existe, lo carga como un DataFrame data usando pd.read_csv.\n",
        "Muestra las primeras filas para verificar la carga correcta.\n",
        "Si no encuentra el archivo, muestra un mensaje de error."
      ],
      "metadata": {
        "id": "GohkmXxorW0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Limpieza de Datos"
      ],
      "metadata": {
        "id": "S0JeNO1rrvMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "wSQvMprprELf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación:\n",
        "\n",
        "Elimina filas que contienen valores nulos para evitar errores durante el entrenamiento.\n",
        "\n",
        "4. Codificación de Variables Categóricas"
      ],
      "metadata": {
        "id": "1KnjqFk7r-GA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_columns = ['Gender', 'City', 'Profession', 'Sleep Duration',\n",
        "                       'Dietary Habits', 'Degree', 'Have you ever had suicidal thoughts ?',\n",
        "                       'Family History of Mental Illness']\n",
        "\n",
        "label_encoders = {}\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    data[col] = le.fit_transform(data[col])\n",
        "    label_encoders[col] = le\n"
      ],
      "metadata": {
        "id": "RZSkDfK5sB05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación:\n",
        "\n",
        "Define columnas categóricas.\n",
        "Usa LabelEncoder para transformar estas columnas en valores numéricos.\n",
        "Almacena cada codificador en label_encoders para referencia futura.\n",
        "\n",
        "5. Normalización de Características Numéricas"
      ],
      "metadata": {
        "id": "9qzs3nG6sGL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_columns = ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA',\n",
        "                     'Study Satisfaction', 'Job Satisfaction', 'Work/Study Hours',\n",
        "                     'Financial Stress']\n",
        "scaler = MinMaxScaler()\n",
        "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n"
      ],
      "metadata": {
        "id": "0wm6Yo7PscDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación:\n",
        "\n",
        "Define columnas numéricas que necesitan ser escaladas.\n",
        "Utiliza MinMaxScaler para escalar los valores a un rango de 0 a 1, mejorando el rendimiento del modelo.\n",
        "\n",
        "6. Preparación de Datos"
      ],
      "metadata": {
        "id": "uhT34L99s3bH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop('Depression', axis=1)\n",
        "y = data['Depression']"
      ],
      "metadata": {
        "id": "M7my-wE8s54m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación:\n",
        "\n",
        "Separa las características (X) eliminando la columna Depression.\n",
        "Define la variable objetivo (y) como la columna Depression.\n",
        "\n",
        "7. División de Datos"
      ],
      "metadata": {
        "id": "iTobXsEHs9R2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "CDRTXElztZya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación:\n",
        "\n",
        "Divide los datos en conjuntos de entrenamiento (70%) y prueba (30%) utilizando train_test_split.\n",
        "Utiliza random_state=42 para garantizar resultados reproducibles.\n",
        "\n",
        "8. Creación y Entrenamiento del Modelo"
      ],
      "metadata": {
        "id": "2qHcF_CKtdGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "L-8ygBtRtjrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación:\n",
        "\n",
        "Crea un modelo RandomForestClassifier.\n",
        "Entrena el modelo usando fit() con los datos de entrenamiento.\n",
        "\n",
        "9. Predicción"
      ],
      "metadata": {
        "id": "uMftX_y_trmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "lFQ9ZE02tyt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación:\n",
        "\n",
        "Realiza predicciones en el conjunto de prueba utilizando predict().\n",
        "\n",
        "10. Evaluación del Modelo"
      ],
      "metadata": {
        "id": "Sjf7Qemtt2VX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, target_names=['No Depression', 'Depression'])\n"
      ],
      "metadata": {
        "id": "p7Lj8EOYuGC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación:\n",
        "\n",
        "Calcula la precisión utilizando accuracy_score.\n",
        "Genera un informe de clasificación detallado usando classification_report.\n",
        "\n",
        "11. Visualización de Resultados"
      ],
      "metadata": {
        "id": "b4aKt05KuLrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Precisión del modelo: {accuracy:.2%}\")\n",
        "print(\"\\nReporte de clasificación:\\n\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "q1iVvv7xuwud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación:\n",
        "\n",
        "Muestra la precisión del modelo en porcentaje.\n",
        "Imprime el informe de clasificación con métricas como precisión, recall y F1-score.\n",
        "Resumen Final\n",
        "El código sigue un flujo estructurado de ciencia de datos que incluye:\n",
        "\n",
        "Carga y Verificación de Datos: Asegura que el archivo está disponible y cargado correctamente.\n",
        "Limpieza de Datos: Elimina datos faltantes para asegurar datos consistentes.\n",
        "Preprocesamiento: Codifica variables categóricas y normaliza valores numéricos.\n",
        "División de Datos: Separa los datos en conjuntos de entrenamiento y prueba.\n",
        "Entrenamiento del Modelo: Crea y entrena un modelo de Random Forest.\n",
        "Predicción y Evaluación: Predice y evalúa el rendimiento mediante métricas estándar."
      ],
      "metadata": {
        "id": "ci2XZtXsu5aJ"
      }
    }
  ]
}