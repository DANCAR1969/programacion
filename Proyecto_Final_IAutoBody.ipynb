{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7yMhzCOqIWWtxci8AYbii",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DANCAR1969/programacion/blob/master/Proyecto_Final_IAutoBody.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxbwYPFcKGNr"
      },
      "outputs": [],
      "source": [
        " Proyecto Final\n",
        "\n",
        "Importar las bibliotecas\n",
        "# Importamos las bibliotecas necesarias\n",
        "import pandas as pd # manipulación y análisis de datos\n",
        "import numpy as np # cálculos numéricos y manejo de matrices\n",
        "import matplotlib.pyplot as plt # generar gráficos\n",
        "import seaborn as sns # visualización de datos con mejores gráficos\n",
        "import spacy # tareas de NLP\n",
        "from sklearn.neighbors import KNeighborsRegressor # modelo K-Nearest Neighbors para regresión\n",
        "from sklearn.preprocessing import StandardScaler # para normalizar los datos\n",
        "from google.colab import drive # para conectar Google Drive en Google Colab\n",
        "drive.mount('/content/drive')\n",
        "# Instalar spaCy para el procesamiento NLP\n",
        "!pip install spacy\n",
        "# Descargar el modelo de lenguaje español\n",
        "!python -m spacy download es_core_news_sm\n",
        "Mostrar el resultado oculto\n",
        "# Cargar el archivo Excel\n",
        "df = pd.read_excel(\"/content/drive/MyDrive/lista materiales cs/LISTA MATERIALES.xlsx\")\n",
        "df.head()\n",
        "print(df.info())\n",
        "Mostrar el resultado oculto\n",
        "Limpieza y organización de los datos existentes\n",
        "# Convertir la columna 'ITEM' a tipo númerico\n",
        "# los errores se convierten en NaN, luego se rellenan con 0 y finalmente se transforman en enteros\n",
        "df['ITEM'] = pd.to_numeric(df['ITEM'], errors='coerce').fillna(0).astype(int)\n",
        "# Convertir la columna referencia a un indice númerico\n",
        "df['OP'] = pd.factorize(df['OP'])[0] + 1 # Asigna un valor numérico único a cada valor distinto en la columna 'OP'\n",
        "# Normalizar texto en columna NIVEL 1\n",
        "# Se estandariza el texto eliminando espacios innecesarios y colocando en mayúsculas\n",
        "def normalize_text(text):\n",
        "if isinstance(text, str): # Verifica si el valor es texto\n",
        "return text.strip().upper() # Elimina espacios en blanco al inicio y final, y convierte el texto a mayúsculas\n",
        "return text # Si no es texto, lo deja igual\n",
        "df['NIVEL 1'] = df['NIVEL 1'].apply(normalize_text)\n",
        "# Ajustar la columna de unidades\n",
        "df['UNIDAD'] = df['UNIDAD'].replace({\n",
        "'UND': 'U', 'MTS': 'm', 'GLS': 'Gal', 'CUA': 'Cuarto',\n",
        "'KIL': 'Kg', 'MT2': 'm2', 'LTS': 'Lt', '#N/A': '0'\n",
        "})\n",
        "# Filtrar ítems que tengan al menos 10 muestras\n",
        "item_counts = df['ITEM'].value_counts() # Cuenta la cantidad de veces que aparece cada 'ITEM'\n",
        "df = df[df['ITEM'].isin(item_counts[item_counts >= 10].index)] # Filtra los 'ITEM' que aparecen al menos 10 veces\n",
        "# Verificar datos nulos para asegurar que la limpieza fue exitosa\n",
        "print(\"Valores nulos por columna después de la limpieza:\")\n",
        "print(df.isnull().sum()) # Muestra la cantidad de valores nulos en cada columna después del proceso\n",
        "# Mostrar las primeras filas para revisar el resultado\n",
        "print(\"\\nPrimeras filas de la tabla limpia:\")\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "Datos_organizados = df\n",
        "20/3/25, 7:22 p.m. PROYECTO FINAL jueves.ipynb - Colab\n",
        "\n",
        "https://colab.research.google.com/drive/17M25Ey4-LJHJOiob2Sccvm3mimd-jZFg#printMode=true 1/9\n",
        "\n",
        "Datos_organizados.to_excel('/content/drive/MyDrive/lista materiales cs/LISTA MATERIALES.xlsx', index=False)\n",
        "print(f\"Datos organizados CNN1 en Excel.\")\n",
        "Mostrar el resultado oculto\n",
        "REVISAMOS LA DISTRIBUCIÓN DE LOS DATOS\n",
        "# Histogramas\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i, col in enumerate(['LARGO EXT (mm)', 'ANCHO EXT (mm)', 'ALTO INTERNO (mm)'], 1): # Itera sobre las tres columnas indicadas\n",
        "plt.subplot(1, 3, i) # Crea subdivisión de 1 fila y 3 columnas, pone cada gráfico en la columna correspondiente\n",
        "sns.histplot(df[col], kde=True, bins=30) # Genera histograma con 30 bins y una curva de densidad (kde)\n",
        "plt.title(f\"Distribución del {col}\") # Título del gráfico\n",
        "plt.xlabel(f\"{col}\") # Etiqueta del eje x\n",
        "plt.ylabel(\"Frecuencia\") # Etiqueta del eje y\n",
        "plt.tight_layout() # Ajusta automáticamente los elementos del gráfico para evitar que se superpongan\n",
        "plt.show()\n",
        "# Diagramas de caja\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i, col in enumerate(['LARGO EXT (mm)', 'ANCHO EXT (mm)', 'ALTO INTERNO (mm)'], 1): # Itera sobre las mismas columnas\n",
        "plt.subplot(1, 3, i) # Crea subdivisión de 1 fila y 3 columnas, pone cada gráfico en la columna correspondiente\n",
        "sns.boxplot(x=df[col], whis=1.5) # Genera un diagrama de caja con un rango de bigotes (whis) del 1.5 veces el IQR (rango intercuartil)\n",
        "plt.title(f\"Diagrama de Cajas - {col}\")\n",
        "plt.xlabel(f\"{col}\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "Generamos datos sinteticos\n",
        "20/3/25, 7:22 p.m. PROYECTO FINAL jueves.ipynb - Colab\n",
        "\n",
        "https://colab.research.google.com/drive/17M25Ey4-LJHJOiob2Sccvm3mimd-jZFg#printMode=true 2/9\n",
        "\n",
        "# Función para generar datos sintéticos\n",
        "def generar_datos_sinteticos(data, n_sinteticos=10000): # Definimos la función\n",
        "np.random.seed(42) # Semilla para reproducibilidad. Asegura que los datos sean siempre los mismos.\n",
        "# Listas para almacenar los datos sintéticos\n",
        "datos_sinteticos = [] # lista vacía\n",
        "# Rango de dimensiones basado en las condiciones dadas\n",
        "largo_min, largo_max = 2500, 8200\n",
        "ancho_min, ancho_max = 1700, 2600\n",
        "alto_min, alto_max = 1400, 3000\n",
        "# Generar datos sintéticos\n",
        "for _ in range(n_sinteticos): # Itera hasta generar la cantidad deseada de datos sintéticos\n",
        "largo = np.random.randint(largo_min, largo_max + 1) # Genera un valor entero aleatorio dentro del rango de largo\n",
        "ancho = np.random.randint(ancho_min, ancho_max + 1) # Genera un valor entero aleatorio dentro del rango de ancho\n",
        "# Generar alto con relación lógica al ancho para evitar carrocerías muy esbeltas\n",
        "if ancho < 2000:\n",
        "alto = np.random.randint(1400, min(2200, 3000) + 1) # Si el ancho es menor a 2000 mm, el alto se limita a máximo 2200 mm\n",
        "elif ancho < 2400:\n",
        "alto = np.random.randint(2000, min(2400, 3000) + 1) # Si el ancho está entre 2000 y 2400 mm, el alto se limita a 2400 mm\n",
        "else:\n",
        "alto = np.random.randint(2200, 3000 + 1) # Si el ancho es mayor o igual a 2400 mm, el alto llega hasta el máximo de 3000 mm\n",
        "# Selección aleatoria de un ítem existente\n",
        "item = np.random.choice(data['ITEM'].unique()) # Selecciona aleatoriamente un ítem único del conjunto de datos original\n",
        "# Determinar unidad y generar cantidad acorde\n",
        "unidad = data[data['ITEM'] == item]['UNIDAD'].iloc[0] # Se obtiene la unidad del ítem seleccionado. iloc selecciona el 1er valor\n",
        "if unidad == 'U':\n",
        "cantidad = np.random.randint(1, 51) # Si la unidad es 'U', genera una cantidad entera entre 1 y 50\n",
        "else:\n",
        "cantidad = round(np.random.uniform(0.5, 20), 2) # Si no es 'U', genera una cantidad decimal entre 0.5 y 20\n",
        "# Agregar fila sintética\n",
        "datos_sinteticos.append([ # Se genera un identificador para la nueva fila sintética\n",
        "f\"OP_SINT_{_+1}\", largo, ancho, alto, # Se agregan las dimensiones generadas\n",
        "data[data['ITEM'] == item]['NIVEL 1'].iloc[0], # Se obtiene el valor de 'NIVEL 1' del ítem seleccionado\n",
        "item,\n",
        "data[data['ITEM'] == item]['MATERIAL'].iloc[0],\n",
        "cantidad,\n",
        "unidad\n",
        "])\n",
        "# Crear DataFrame con los datos generados\n",
        "columnas = data.columns # Se obtiene la lista de columnas del DataFrame original\n",
        "datos_sinteticos_df = pd.DataFrame(datos_sinteticos, columns=columnas) # Se crea el DataFrame con los datos sintéticos\n",
        "return datos_sinteticos_df\n",
        "# Generar datos sintéticos\n",
        "datos_sinteticos = generar_datos_sinteticos(df)\n",
        "# Combinar los datos originales con los datos sintéticos\n",
        "datos_combinados = pd.concat([df, datos_sinteticos], ignore_index=True) # Concatena ambos df\n",
        "# Exportar el resultado a un nuevo archivo Excel\n",
        "datos_combinados.to_excel(\"/content/drive/MyDrive/lista materiales cs/LISTA MATERIALES.xlsx\", index=False)\n",
        "print(\"✅ Datos sintéticos generados y exportados correctamente.\")\n",
        "✅ Datos sintéticos generados y exportados correctamente.\n",
        "Código ajustado en columna unidades para entregar la predicción\n",
        "# Cargar el archivo Excel\n",
        "df = pd.read_excel(\"/content/drive/MyDrive/lista materiales cs/LISTA MATERIALES.xlsx\")\n",
        "# Renombrar columnas para mayor claridad\n",
        "df.columns = ['OP', 'LARGO_EXT', 'ANCHO_EXT', 'ALTO_INTERNO', 'NIVEL', 'ITEM', 'MATERIAL', 'CANTIDAD', 'UNIDAD']\n",
        "# Limpiar y convertir columnas numéricas\n",
        "20/3/25, 7:22 p.m. PROYECTO FINAL jueves.ipynb - Colab\n",
        "\n",
        "https://colab.research.google.com/drive/17M25Ey4-LJHJOiob2Sccvm3mimd-jZFg#printMode=true 3/9\n",
        "\n",
        "df['LARGO_EXT'] = pd.to_numeric(df['LARGO_EXT'], errors='coerce')\n",
        "df['ANCHO_EXT'] = pd.to_numeric(df['ANCHO_EXT'], errors='coerce')\n",
        "df['ALTO_INTERNO'] = pd.to_numeric(df['ALTO_INTERNO'], errors='coerce')\n",
        "df['CANTIDAD'] = pd.to_numeric(df['CANTIDAD'], errors='coerce')\n",
        "# Eliminar filas con valores faltantes en columnas clave\n",
        "df = df.dropna(subset=['LARGO_EXT', 'ANCHO_EXT', 'ALTO_INTERNO', 'ITEM', 'CANTIDAD'])\n",
        "# Crear diccionario de items para nombres y unidades\n",
        "items_dict = {} # diccionario vacío para información clave de cada ITEM.\n",
        "unique_items = sorted(df['ITEM'].unique()) # lista de todos los valores únicos en la columna ITEM, ordenados de menor a mayor.\n",
        "for item in unique_items:\n",
        "item_rows = df[df['ITEM'] == item] # filtra el df para obtener solo las filas que contienen el ITEM actual en el bucle.\n",
        "if not item_rows.empty: # Esta condición evita que se intente acceder a un DataFrame vacío\n",
        "items_dict[item] = { # se crea una entrada en el diccionario\n",
        "'name': item_rows['MATERIAL'].iloc[0],\n",
        "'unit': item_rows['UNIDAD'].iloc[0]\n",
        "}\n",
        "# Entrenar modelos para cada item\n",
        "X_cols = ['LARGO_EXT', 'ANCHO_EXT', 'ALTO_INTERNO'] # variables de entrada\n",
        "scaler = StandardScaler()\n",
        "model_dict = {} # Diccionario vacío donde se guardarán los modelos entrenados para cada ITEM\n",
        "for item in unique_items: # Filtrar las filas del DataFrame que correspondan al ITEM actual\n",
        "item_data = df[df['ITEM'] == item]\n",
        "if len(item_data) < 3: # Si hay menos de 3, se omite (evita problemas en el entrenamiento)\n",
        "continue\n",
        "# Extraer las columnas de entrada (largo, ancho y alto) como matriz de datos (X)\n",
        "X = item_data[X_cols].values # `.values` convierte el DataFrame en un array de NumPy para el modelo\n",
        "# Extraer la columna 'CANTIDAD' como vector objetivo (y)\n",
        "y = item_data['CANTIDAD'].values\n",
        "# Normalizar los datos de entrada para que todas las variables estén en la misma escala\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "# Determinar el número óptimo de vecinos para el modelo KNN\n",
        "# Se selecciona el mínimo entre 5 y la mitad del total de datos, asegurando al menos 1 vecino\n",
        "k = min(5, max(1, len(item_data) // 2))\n",
        "# Crear el modelo KNN con el número de vecinos determinado y asignar pesos según la distancia\n",
        "model = KNeighborsRegressor(n_neighbors=k, weights='distance')\n",
        "model.fit(X_scaled, y) # Entrena el modelo con los datos normalizados y el vector objetivo\n",
        "model_dict[item] = model # Guardar el modelo entrenado en el diccionario usando el ITEM como clave\n",
        "# --- Ingreso de datos para predicción ---\n",
        "print(\"Ingrese las dimensiones de la carrocería:\")\n",
        "length = float(input(\"Largo (mm): \"))\n",
        "width = float(input(\"Ancho (mm): \"))\n",
        "height = float(input(\"Alto (mm): \"))\n",
        "# Vector de entrada escalado\n",
        "X_input = np.array([[length, width, height]])\n",
        "X_input_scaled = scaler.transform(X_input)\n",
        "# Palabras clave para cantidades en números enteros\n",
        "elementos_enteros = [\"TORNILLO\", \"TUERCA\", \"WASA\", \"ARANDELA\", \"BISAGRA\", \"TERMINAL\", \"SWITCH\",\n",
        "\"LAMPARA\", \"BROCA\", \"FUSIBLE\", \"BREAKER\", \"PORTA RELAY\", \"LIJA\", \"DISCO VELCRO\",\n",
        "\"PANOS\", \"AMARRA\", \"PUBLICIDAD\", \"REMACHE\", \"SOUDAFLEX\", \"CINTA\", \"REGLETA\", \"INMOVILIZADOR\", \"DISCO\", \"SIKA FLEX\", \"VA\n",
        "\n",
        "# Predicción de materiales\n",
        "results = []\n",
        "for item, model in model_dict.items(): # Iterar sobre cada item y su modelo en el diccionario de modelos\n",
        "predicted_qty = max(0, model.predict(X_input_scaled)[0]) # Se toma el primer valor de la predicción y se asegura que no sea negativo (se\n",
        "if predicted_qty > 0.1: # Si la cantidad es mayor a 0.1, se considera válida\n",
        "# Obtener el nombre del ítem en mayúsculas y su unidad de medida\n",
        "item_name = items_dict[item]['name'].upper()\n",
        "unit = items_dict[item]['unit']\n",
        "# Verificar si el nombre del ítem coincide con algún elemento en 'elementos_enteros'\n",
        "# Si es así, se redondea a un número entero (evita decimales en elementos como tornillos o arandelas)\n",
        "if any(elemento in item_name for elemento in elementos_enteros):\n",
        "predicted_qty = round(predicted_qty)\n",
        "# Si la unidad de medida es 'UND', también se redondea a entero\n",
        "elif unit == 'UND':\n",
        "predicted_qty = round(predicted_qty)\n",
        "\n",
        "20/3/25, 7:22 p.m. PROYECTO FINAL jueves.ipynb - Colab\n",
        "\n",
        "https://colab.research.google.com/drive/17M25Ey4-LJHJOiob2Sccvm3mimd-jZFg#printMode=true 4/9\n",
        "\n",
        "# Si no cumple ninguna de las condiciones anteriores, se redondea a 2 decimales\n",
        "else:\n",
        "predicted_qty = round(predicted_qty, 2)\n",
        "# Si la cantidad predicha es mayor que cero, se agrega a la lista de resultados\n",
        "if predicted_qty > 0:\n",
        "results.append({\n",
        "'ITEM': item,\n",
        "'MATERIAL': items_dict[item]['name'],\n",
        "'CANTIDAD REQUERIDA': predicted_qty,\n",
        "'UNIDAD': unit\n",
        "})\n",
        "# Crear DataFrame con resultados\n",
        "results_df = pd.DataFrame(results)\n",
        "# Exportar a Excel\n",
        "output_path = \"/content/drive/MyDrive/lista materiales cs/Resultados_Prediccion_Claude 1.xlsx\"\n",
        "results_df.to_excel (output_path, index=False)\n",
        "print(f\"Resultados exportados a {output_path}\")\n",
        "\n",
        "Ingrese las dimensiones de la carrocería:\n",
        "Largo (mm): 3400\n",
        "Ancho (mm): 2000\n",
        "Alto (mm): 1780\n",
        "Resultados exportados a /content/drive/MyDrive/lista materiales cs/Resultados_Prediccion_Claude 1.xlsx\n",
        "\n",
        "Realizar un análisis comparativo entre los materiales en stock y la predicción de materiales para la fabricacion de un furgon carga seca.\n",
        " Comparación de datos\n",
        "\n",
        "# Cargar las hojas de cálculo en DataFrames de Pandas\n",
        "stock_df = pd.read_excel(\"/content/drive/MyDrive/Stock/STOCK DE MATERIALES.xlsx\")\n",
        "prediccion_df = pd.read_excel(\"/content/drive/MyDrive/lista materiales cs/Resultados_Prediccion_Claude 1.xlsx\")\n",
        "# Diccionario de abreviaciones para las unidades\n",
        "abreviaturas = {\n",
        "'UND': 'U',\n",
        "'MTS': 'm',\n",
        "'GLS': 'Gal',\n",
        "'CUA': 'Cuarto',\n",
        "'KIL': 'Kg',\n",
        "'MT2': 'm2',\n",
        "'LTS': 'Lt',\n",
        "'#N/A': '0'\n",
        "}\n",
        "# Reemplazar las unidades en la columna 'UNIDAD' según el diccionario\n",
        "stock_df['UNIDAD'] = stock_df['UNIDAD'].map(abreviaturas).fillna(stock_df['UNIDAD'])\n",
        "# Convertir las columnas a tipo numérico (en caso de que haya valores no numéricos)\n",
        "stock_df['CANTIDAD EN STOCK'] = pd.to_numeric(stock_df['CANTIDAD EN STOCK'], errors='coerce')\n",
        "prediccion_df['CANTIDAD REQUERIDA'] = pd.to_numeric(prediccion_df['CANTIDAD REQUERIDA'], errors='coerce')\n",
        "# Reemplazar valores nulos en la columna 'CANTIDAD EN STOCK' por un valor predeterminado (por ejemplo, 0)\n",
        "stock_df['CANTIDAD EN STOCK'] = stock_df['CANTIDAD EN STOCK'].fillna(0)\n",
        "# Función para comparar el stock con la predicción\n",
        "def comparar_stock_con_prediccion(stock_df, prediccion_df):\n",
        "# Asegurarse de que los nombres de las columnas coincidan (eliminando espacios extra)\n",
        "stock_df.columns = stock_df.columns.str.strip()\n",
        "prediccion_df.columns = prediccion_df.columns.str.strip()\n",
        "# Realizar un merge(Union) entre las dos hojas por la columna \"MATERIAL\"\n",
        "comparacion_df = pd.merge(prediccion_df, stock_df, how='left', on='MATERIAL')\n",
        "# Añadir una columna para comparar si hay suficiente stock\n",
        "comparacion_df['Suficiente Stock'] = comparacion_df['CANTIDAD EN STOCK'] >= comparacion_df['CANTIDAD REQUERIDA']\n",
        "# Añadir una columna para la cantidad faltante (si la hay)\n",
        "comparacion_df['Cantidad Faltante'] = comparacion_df['CANTIDAD REQUERIDA'] - comparacion_df['CANTIDAD EN STOCK']\n",
        "comparacion_df['Cantidad Faltante'] = comparacion_df['Cantidad Faltante'].apply(lambda x: x if x > 0 else 0)\n",
        "20/3/25, 7:22 p.m. PROYECTO FINAL jueves.ipynb - Colab\n",
        "\n",
        "https://colab.research.google.com/drive/17M25Ey4-LJHJOiob2Sccvm3mimd-jZFg#printMode=true 5/9\n",
        "\n",
        "# Crear una columna de \"Estado\" que diga si el material está disponible o no\n",
        "comparacion_df['Estado'] = comparacion_df['Suficiente Stock'].apply(lambda x: \"Suficiente stock\" if x else \"No hay suficiente stock\")\n",
        "return comparacion_df\n",
        "# Llamar a la función para comparar stock con predicción\n",
        "resultado_comparacion = comparar_stock_con_prediccion(stock_df, prediccion_df)\n",
        "# Asegurarse de que la comparación se realizó correctamente\n",
        "if resultado_comparacion is not None and not resultado_comparacion.empty:\n",
        "# Mostrar el resultado\n",
        "print(\"\\nResultado de la comparación:\")\n",
        "print(resultado_comparacion)\n",
        "# Guardar el resultado en un archivo Excel\n",
        "resultado_comparacion.to_excel(\"/content/drive/MyDrive/resultado_comparacion.xlsx\", index=False)\n",
        "print(\"El archivo se ha guardado correctamente.\")\n",
        "else:\n",
        "print(\"No se pudo generar el archivo debido a que la comparación no produjo resultados válidos.\")\n",
        "Mostrar el resultado oculto\n",
        "El resultado es un análisis que muestra si hay stock su\n",
        "\n",
        "ciente para satisfacer la demanda predicha y calcular cualquier falta de material.\n",
        "\n",
        "Indicar qué materiales faltan en el stock para la fabricacion del furgon y cómo gestionar el pedido.\n",
        " Análisis de datos y NLP(Procesamiento de lenguaje Natural)\n",
        "\n",
        "# Cargar el archivo Excel en un DataFrame\n",
        "stock_df = pd.read_excel(\"/content/drive/MyDrive/resultado_comparacion.xlsx\")\n",
        "# Diccionario de abreviaturas para las unidades de medición\n",
        "abreviaturas = {\n",
        "'UND': 'U',\n",
        "'MTS': 'm',\n",
        "'GLS': 'Gal',\n",
        "'CUA': 'Cuarto',\n",
        "'KIL': 'Kg',\n",
        "'MT2': 'm2',\n",
        "'LTS': 'Lt',\n",
        "'#N/A': '0'\n",
        "}\n",
        "# Función para generar un mensaje con los materiales faltantes y su unidad de medición\n",
        "def generar_mensaje_nlp(comparacion_df):\n",
        "mensaje = \"Se requiere solicitar los siguientes materiales debido a que el stock es insuficiente:\\n\\n\"\n",
        "# Filtrar los materiales que faltan (solo aquellos con 'Cantidad Faltante' mayor a 0)\n",
        "materiales_faltantes = comparacion_df[comparacion_df['Cantidad Faltante'] > 0]\n",
        "# Repite los materiales faltantes y generar el mensaje\n",
        "for index, row in materiales_faltantes.iterrows():\n",
        "material = row['MATERIAL']\n",
        "cantidad_faltante = row['Cantidad Faltante']\n",
        "unidad = row['UNIDAD_x'] # Usamos la columna de unidad correspondiente\n",
        "# Obtener la unidad abreviada usando el diccionario\n",
        "unidad_abreviada = abreviaturas.get(unidad, unidad) # Si no está en el diccionario, se usa el valor original\n",
        "# Agregar al mensaje el material, cantidad faltante y la unidad de medición\n",
        "mensaje += f\"- {material}: {cantidad_faltante} {unidad_abreviada}\\n\"\n",
        "mensaje += \"\\nFavor de gestionar el pedido lo antes posible.\"\n",
        "return mensaje\n",
        "# Llamar a la función para generar el mensaje\n",
        "mensaje_generado = generar_mensaje_nlp(stock_df)\n",
        "# Imprimir el mensaje generado\n",
        "print(mensaje_generado)\n",
        "Mostrar el resultado oculto\n",
        "20/3/25, 7:22 p.m. PROYECTO FINAL jueves.ipynb - Colab\n",
        "\n",
        "https://colab.research.google.com/drive/17M25Ey4-LJHJOiob2Sccvm3mimd-jZFg#printMode=true 6/9\n",
        "\n",
        " GAN Condicional\n",
        " Generación de imágenes sintéticas\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "def generate_synthetic_image(output_path, width, height, vertical_bars, horizontal_bars):\n",
        "image = np.ones((4000, 4000, 3), dtype=np.uint8) * 255 # Fondo blanco\n",
        "x1 = (4000 - width) // 2 # Centrar rectángulo en el lienzo\n",
        "y1 = (4000 - height) // 2\n",
        "# Dibuja el rectángulo grande con tamaño dinámico\n",
        "border_thickness = 3\n",
        "cv2.rectangle(image, (x1, y1), (x1 + width, y1 + height), (0, 0, 0), border_thickness)\n",
        "# Tamaño fijo de las barras\n",
        "bar_height = 80 # Altura de barras horizontales\n",
        "bar_width = 80 # Ancho de barras verticales\n",
        "# Espacio disponible para distribuir barras\n",
        "available_height = height - 2 * bar_height # Espacio sin contar las barras superior e inferior\n",
        "available_width = width - 2 * bar_width # Espacio sin contar las barras de los extremos\n",
        "# Distribuir barras horizontales (siempre 2 en los extremos, resto equidistantes)\n",
        "for i in range(horizontal_bars):\n",
        "if i == 0: # Primera barra (arriba)\n",
        "y = y1\n",
        "elif i == horizontal_bars - 1: # Última barra (abajo)\n",
        "y = y1 + height - bar_height\n",
        "else: # Barras intermedias\n",
        "y = y1 + bar_height + (i - 1) * (available_height // (horizontal_bars - 2))\n",
        "cv2.rectangle(image, (x1, y), (x1 + width, y + bar_height), (255, 0, 0), -1)\n",
        "# Distribuir barras verticales (siempre 2 en los extremos, resto equidistantes)\n",
        "for i in range(vertical_bars):\n",
        "if i == 0: # Primera barra (izquierda)\n",
        "x = x1\n",
        "elif i == vertical_bars - 1: # Última barra (derecha)\n",
        "x = x1 + width - bar_width\n",
        "else: # Barras intermedias\n",
        "x = x1 + bar_width + (i - 1) * (available_width // (vertical_bars - 2))\n",
        "cv2.rectangle(image, (x, y1), (x + bar_width, y1 + height), (0, 0, 255), -1)\n",
        "# Guardar la imagen generada\n",
        "cv2.imwrite(output_path, image)\n",
        "# Crear carpeta para guardar imágenes\n",
        "output_folder = \"imagenessinteticas\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "for i in range(3000):\n",
        "width = random.randint(1400, 2600)\n",
        "height = random.randint(1400, 2800)\n",
        "# Definir el número mínimo y máximo de barras basado en el tamaño\n",
        "max_horizontal_bars = min(10, (height - 2 * 80) // 100 + 2) # Mínimo 2, máximo ajustado al espacio\n",
        "max_vertical_bars = min(10, (width - 2 * 80) // 100 + 2) # Mínimo 2, máximo ajustado al espacio\n",
        "horizontal_bars = random.randint(2, max_horizontal_bars)\n",
        "vertical_bars = random.randint(2, max_vertical_bars)\n",
        "output_path = os.path.join(output_folder, f\"image_{i+1}.png\")\n",
        "generate_synthetic_image(output_path, width, height, vertical_bars, horizontal_bars)\n",
        "20/3/25, 7:22 p.m. PROYECTO FINAL jueves.ipynb - Colab\n",
        "\n",
        "https://colab.research.google.com/drive/17M25Ey4-LJHJOiob2Sccvm3mimd-jZFg#printMode=true 7/9\n",
        "\n",
        " GAN\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "# Parámetros\n",
        "IMG_SHAPE = (64, 64, 1) # Tamaño de las imágenes\n",
        "NOISE_DIM = 100 # Dimensión del ruido\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5000\n",
        "# Rango de dimensiones de los rectángulos\n",
        "WIDTH_RANGE = (10, 50) # Ancho mínimo y máximo\n",
        "HEIGHT_RANGE = (10, 50) # Alto mínimo y máximo\n",
        "# Cargar dataset de imágenes de rectángulos\n",
        "def load_data():\n",
        "data = []\n",
        "folder = \"/content/imagenessinteticas\"\n",
        "for file in os.listdir(folder):\n",
        "img = tf.keras.preprocessing.image.load_img(os.path.join(folder, file), color_mode=\"grayscale\", target_size=IMG_SHAPE[:2])\n",
        "img = np.array(img) / 127.5 - 1 # Normalización a [-1, 1]\n",
        "data.append(img)\n",
        "return np.expand_dims(np.array(data), axis=-1)\n",
        "# Generador modificado para incluir width y height\n",
        "def build_generator():\n",
        "input_noise = keras.Input(shape=(NOISE_DIM,))\n",
        "input_width = keras.Input(shape=(1,))\n",
        "input_height = keras.Input(shape=(1,))\n",
        "# Concatenar ruido con dimensiones normalizadas\n",
        "merged_input = layers.Concatenate()([input_noise, input_width, input_height])\n",
        "x = layers.Dense(8 * 8 * 128, activation=\"relu\")(merged_input)\n",
        "x = layers.Reshape((8, 8, 128))(x)\n",
        "x = layers.Conv2DTranspose(128, kernel_size=7, strides=2, padding=\"same\", activation='relu')(x)\n",
        "x = layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\", activation='relu')(x)\n",
        "x = layers.Conv2DTranspose(1, kernel_size=4, strides=2, padding=\"same\", activation='tanh')(x)\n",
        "return keras.Model([input_noise, input_width, input_height], x)\n",
        "# Discriminador (sin cambios)\n",
        "def build_discriminator():\n",
        "model = keras.Sequential([\n",
        "layers.Conv2D(64, kernel_size=7, strides=2, padding=\"same\", input_shape=IMG_SHAPE),\n",
        "layers.LeakyReLU(alpha=0.2),\n",
        "layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "layers.LeakyReLU(alpha=0.2),\n",
        "layers.Flatten(),\n",
        "layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "return model\n",
        "# Construcción de la GAN\n",
        "def build_gan(generator, discriminator):\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(0.0002, 0.5), metrics=['accuracy'])\n",
        "discriminator.trainable = False\n",
        "noise_input = keras.Input(shape=(NOISE_DIM,))\n",
        "width_input = keras.Input(shape=(1,))\n",
        "height_input = keras.Input(shape=(1,))\n",
        "fake_img = generator([noise_input, width_input, height_input])\n",
        "gan_output = discriminator(fake_img)\n",
        "gan = keras.Model([noise_input, width_input, height_input], gan_output)\n",
        "gan.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(0.0002, 0.5))\n",
        "return gan\n",
        "# Entrenar GAN\n",
        "20/3/25, 7:22 p.m. PROYECTO FINAL jueves.ipynb - Colab\n",
        "\n",
        "https://colab.research.google.com/drive/17M25Ey4-LJHJOiob2Sccvm3mimd-jZFg#printMode=true 8/9\n",
        "\n",
        "def train_gan(generator, discriminator, gan, dataset, epochs=EPOCHS, batch_size=BATCH_SIZE):\n",
        "half_batch = batch_size // 2\n",
        "for epoch in range(epochs):\n",
        "# Entrenar el discriminador con imágenes reales y falsas\n",
        "idx = np.random.randint(0, dataset.shape[0], half_batch)\n",
        "real_imgs = dataset[idx]\n",
        "# Generar ruido y dimensiones aleatorias\n",
        "noise = np.random.normal(0, 1, (half_batch, NOISE_DIM))\n",
        "widths = np.random.uniform(WIDTH_RANGE[0], WIDTH_RANGE[1], (half_batch, 1)) / IMG_SHAPE[1]\n",
        "heights = np.random.uniform(HEIGHT_RANGE[0], HEIGHT_RANGE[1], (half_batch, 1)) / IMG_SHAPE[0]\n",
        "fake_imgs = generator.predict([noise, widths, heights])\n",
        "d_loss_real = discriminator.train_on_batch(real_imgs, np.ones((half_batch, 1)))\n",
        "d_loss_fake = discriminator.train_on_batch(fake_imgs, np.zeros((half_batch, 1)))\n",
        "d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "# Entrenar el generador para engañar al discriminador\n",
        "noise = np.random.normal(0, 1, (batch_size, NOISE_DIM))\n",
        "widths = np.random.uniform(WIDTH_RANGE[0], WIDTH_RANGE[1], (batch_size, 1)) / IMG_SHAPE[1]\n",
        "heights = np.random.uniform(HEIGHT_RANGE[0], HEIGHT_RANGE[1], (batch_size, 1)) / IMG_SHAPE[0]\n",
        "g_loss = gan.train_on_batch([noise, widths, heights], np.ones((batch_size, 1)))\n",
        "if epoch % 500 == 0:\n",
        "print(f\"Epoch {epoch}, D Loss: {d_loss[0]}, G Loss: {g_loss}\")\n",
        "save_generated_image(generator, epoch)\n",
        "# Guardar imágenes generadas\n",
        "def save_generated_image(generator, epoch):\n",
        "noise = np.random.normal(0, 1, (1, NOISE_DIM))\n",
        "width = np.array([[np.random.uniform(WIDTH_RANGE[0], WIDTH_RANGE[1]) / IMG_SHAPE[1]]])\n",
        "height = np.array([[np.random.uniform(HEIGHT_RANGE[0], HEIGHT_RANGE[1]) / IMG_SHAPE[0]]])\n",
        "generated_img = generator.predict([noise, width, height])[0]\n",
        "generated_img = (generated_img + 1) / 2 # Desnormalizar a [0, 1]\n",
        "plt.imshow(generated_img.squeeze(), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.savefig(f\"generated/epoch_{epoch}.png\")\n",
        "plt.close()\n",
        "# Ejecutar entrenamiento\n",
        "if __name__ == \"__main__\":\n",
        "dataset = load_data()\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "gan = build_gan(generator, discriminator)\n",
        "os.makedirs(\"generated\", exist_ok=True)\n",
        "train_gan(generator, discriminator, gan, dataset)"
      ]
    }
  ]
}